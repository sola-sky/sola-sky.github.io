---
title: 音视频同步技术
date: 2017-02-06 08:45:24
tags:
---

## 1.问题的产生

在项目中遇到的一个问题就是音视频不同步，直接的现象是：在回放车辆上的视频时出现了，离视频结束还有一段时间时只有画面没有声音了。导致这个问题的根本原因就是音视频不同步，原先做这块没有经验，视频只管视频自己，音频只管音频自己，而视频解析和渲染的过程中有些帧很耗时，导致了视频时间线上慢慢与音频时间线差距变大，最终出现音频播放了视频还有一段没有播。因此很有必要实行音视频同步。

## 2. 时间戳同步

上网查找了音视频同步的解决方案后，决定采取时间戳的方式进行同步，这其中就要涉及PTS和DTS了，还会涉及到I、P、B帧等概念，具体的概念自己上网查找。

而采用时间戳同步时主要有三种：

- 视频同步到音频时钟
- 音频同步到视频时钟
- 音视频同步到外部时钟

项目中最终采用视频同步到音频时间的方案，因为人对于声音的分辨要高于视频的分辨，如果对声音进行处理很大概率会引起在观看过程中的不舒适。

### 1. 抽象层次上的音视频同步算法

音频部分：

![](http://okxoqauma.bkt.clouddn.com/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%90%8C%E6%AD%A5%E2%80%94%E2%80%94%E9%9F%B3%E9%A2%91%E9%83%A8%E5%88%86.png)

视频部分：

![](http://okxoqauma.bkt.clouddn.com/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%90%8C%E6%AD%A5%E2%80%94%E2%80%94%E8%A7%86%E9%A2%91%E9%83%A8%E5%88%86.png)

总结：

视频同步到音频时，主要对比两者的时间钟，然后计算出视频应该延迟多长时间播放，再计算视频当前帧应该播放的时间点跟系统当前时间的情况，如果还未到播放时间点则延迟，如果已经到了播放时间点则播放，如果已经远远落后了则丢掉该帧。

### 2. 具体的音视频同步

既然要对比音频和视频各自播放的时间，那么就需要记录当前音频和视频播放的时间戳

![](http://okxoqauma.bkt.clouddn.com/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%90%8C%E6%AD%A5%E2%80%94%E2%80%94%E6%97%B6%E9%92%9F%E7%B1%BB.png)

这里只列出了一部分成员和操作，其中`pts_`用于记录当前播放到的视频或者音频本身对应帧的时间戳，`GetClock()`用于获取时间戳，而`SetClock()`用于设置时间戳（每播放一帧后都会重新设置相应的时间戳）。

接下来我们看看具体的代码：

```C++
     void VideoState::VideoRefresh(FFPlayer *player, double *remaining_time) {
           	double time; //用于记录系统时间
 			··· ···
   
            double last_duration, duration, delay;
            Frame *vp, *lastvp; // lastvp代表上一帧，vp代表即将要显示的这一帧

            lastvp = pictq_->FrameQueuePeekLast(); //从缓存中获取上一帧
            vp = pictq_->FrameQueuePeek(); //从缓存中获取即将要显示的这一帧
            ··· ···

            last_duration = FrameDuration(lastvp, vp);  //计算两视频帧间的间隔
            delay = ComputeTargetDelay(last_duration); //根据视频时间钟与音频时间钟之间的差值，调节需要延迟的时间

            time = av_gettime_relative() / 1000000.0; //获取系统当前时间
 			··· ··· 
            
            // frame_timer_ 会一直累加播放过程中我们计算的时延，这里相当于上一次刷新视频帧的时间
            // 于是这里frame_timer_ + delay表示的是这一帧视频应该刷新的时间点
            if (time < frame_timer_ + delay) { 
                // 代表当前系统时间还未到这一帧视频的刷新时间，于是计算需要休眠的时间以便等到刷新时间点的到来
                *remaining_time = FFMIN(frame_timer_ + delay - time, *remaining_time);
                goto display;
            }

            frame_timer_ += delay; // frame_timer_ 累加时延
       
       		··· ···

            pthread_mutex_lock(pictq_->mutex());
            if (!isnan(vp->pts_)) {
                UpdateVideoPts(vp->pts_, vp->pos_, vp->serial_); // 这里最终调用上文提到的Clock类中的设置时间戳函数，用来更新最新一帧视频播放时对应的PTS
            }
            pthread_mutex_unlock(pictq_->mutex());

            if (pictq_->FrameQueueNbRemaining() > 1) { // 如果视频缓存中还有下一帧视频
                Frame *nextvp = pictq_->FrameQueuePeekNext(); // 提取下一帧视频
                duration = FrameDuration(vp, nextvp); 
                if (!step_
                    && (player->framedrop() > 0 ||
                        (player->framedrop() && GetMasterSyncType() != AV_SYNC_VIDEO_MASTER))
                    && time > frame_timer_ + duration) { //这里主要看 time > frame_timer_ + duration这个判断就行，这里代表意思是如果下一帧视频渲染的时间点都比当前系统时间慢，也就是说视频已经慢了起码2帧了，那么就直接把当前帧丢掉不进行渲染，以此加快播放速度
                    frame_drops_late_++;
                    pictq_->FrameQueueNext(); // 缓存移到下一帧
                    goto retry; // 重新进行渲染判断
                }
            }
       
       ··· ··· 
       ··· ···
     }
```

这段代码已经注释的很详细了，接下来我们看看其中调用到的`ComputeTargetDelay(last_duration)`，其具体代码如下：

```C++
double VideoState::ComputeTargetDelay(double delay) {
    double sync_threshold, diff = 0;
    if (GetMasterSyncType() != AV_SYNC_VIDEO_MASTER) { // 当选择的同步不是同步到视频时，可以理解为当前的同步是视频同步到音频
        diff = vidclk_->GetClock() - GetMasterClock(); // 计算视频钟的时间戳与音频钟的时间戳的差值
        sync_threshold = FFMAX(AV_SYNC_THRESHOLD_MIN, FFMIN(AV_SYNC_THRESHOLD_MAX, delay));
      
        /* 下面的逻辑主要是调节延迟时间，当视频播放比音频快，则加大视频下一帧渲染的延迟时间；如果音频播放的比视频快，则缩短延迟时间，加快渲染
        */
        if (!isnan(diff) && fabs(diff) < AV_NOSYNC_THRESHOLD) {
            if (diff <= -sync_threshold) { 
                delay = FFMAX(0, delay + diff);
            } else if (diff >= sync_threshold && delay > AV_SYNC_FRAMEDUP_THRESHOLD) {
                delay = delay + diff;
            } else if (diff >= sync_threshold) { 
                delay = 2 * delay;
            }
        }
    }

    return delay;
}
```

总结：

音视频同步技术其实就是尽可能保持音频和视频的PTS的在允许的范围内保持同步。当视频快了，则延长休眠时间，增大下一帧视频渲染的时间间隔；慢了则缩短休眠时间甚至是直接丢帧，以此加快渲染。

## 3.参考

[视频同步](http://www.samirchen.com/ffmpeg-tutorial-5/)